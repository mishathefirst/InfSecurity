{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Генерация тренировочного и тестового датасетов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируем нужные библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import classification_report\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прочитаем предварительно обработанный датасет и удалим все строки, с пропусками"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>date</th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>subject</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>info@global-change.com</td>\n",
       "      <td>michelle.lokay@enron.com</td>\n",
       "      <td>next wave energi trade</td>\n",
       "      <td>energi industri profession global chang associ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>info@pmaconference.com</td>\n",
       "      <td>michelle.lokay@enron.com</td>\n",
       "      <td>regist next txu capac auction</td>\n",
       "      <td>regist next txu energi capac auction new regis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>info@pmaconference.com</td>\n",
       "      <td>michelle.lokay@enron.com</td>\n",
       "      <td>merchant power monthli free sampl</td>\n",
       "      <td>merchant power monthli month s issu almost mw ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>bruno@firstconf.com</td>\n",
       "      <td>energynews@fc.ease.lsoft.com</td>\n",
       "      <td>eyeforenergi updat</td>\n",
       "      <td>welcom week s eyeforenergi updat refresh memor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>deanrogers@energyclasses.com</td>\n",
       "      <td>michelle.lokay@enron.com</td>\n",
       "      <td>deriv earli bird til march houston</td>\n",
       "      <td>deriv energi profession two full day april ear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30687</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>jacob rzucidlo &lt;lavoneaker@stalag13.com&gt;</td>\n",
       "      <td>johnny wynott &lt;varou@iit.demokritos.gr&gt;</td>\n",
       "      <td>cpu pain m edicati n ship d r</td>\n",
       "      <td>arrghh west amnstv amlsmith basu petrom qureai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30688</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>hal leake &lt;annettgaskell@buglover.net&gt;</td>\n",
       "      <td>renato mooney &lt;sigletos@iit.demokritos.gr&gt;</td>\n",
       "      <td>dn troubl f r ee</td>\n",
       "      <td>dn troubl f r ee angiospasma zekauskasa anarti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30689</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>dr collins khumalo &lt;khumalo_20@sunumail.sn&gt;</td>\n",
       "      <td>khumalo_20@sunumail.sn</td>\n",
       "      <td>dr collin khumalo</td>\n",
       "      <td>dr collin khumalo attn mr presid dr collin khu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30690</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>Customer Support &lt;support@citibank.com&gt;</td>\n",
       "      <td>Paliourg &lt;paliourg@iit.demokritos.gr&gt;</td>\n",
       "      <td>dear custom detail compromis</td>\n",
       "      <td>dear custom detail compromis dear custom recen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30691</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>Tapanga Cribbin &lt;James_Lam@cnwl.igs.net&gt;</td>\n",
       "      <td>paliourg@iit.demokritos.gr</td>\n",
       "      <td>fwd great news</td>\n",
       "      <td>state shall without consent congress lay impos...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29890 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       class  date                                         from  \\\n",
       "0          0     4                       info@global-change.com   \n",
       "1          0     1                       info@pmaconference.com   \n",
       "2          0     6                       info@pmaconference.com   \n",
       "3          0     3                          bruno@firstconf.com   \n",
       "4          0     1                 deanrogers@energyclasses.com   \n",
       "...      ...   ...                                          ...   \n",
       "30687      1     3     jacob rzucidlo <lavoneaker@stalag13.com>   \n",
       "30688      1     5       hal leake <annettgaskell@buglover.net>   \n",
       "30689      1     2  dr collins khumalo <khumalo_20@sunumail.sn>   \n",
       "30690      1     6      Customer Support <support@citibank.com>   \n",
       "30691      1     6     Tapanga Cribbin <James_Lam@cnwl.igs.net>   \n",
       "\n",
       "                                               to  \\\n",
       "0                        michelle.lokay@enron.com   \n",
       "1                        michelle.lokay@enron.com   \n",
       "2                        michelle.lokay@enron.com   \n",
       "3                    energynews@fc.ease.lsoft.com   \n",
       "4                        michelle.lokay@enron.com   \n",
       "...                                           ...   \n",
       "30687     johnny wynott <varou@iit.demokritos.gr>   \n",
       "30688  renato mooney <sigletos@iit.demokritos.gr>   \n",
       "30689                      khumalo_20@sunumail.sn   \n",
       "30690       Paliourg <paliourg@iit.demokritos.gr>   \n",
       "30691                  paliourg@iit.demokritos.gr   \n",
       "\n",
       "                                  subject  \\\n",
       "0                  next wave energi trade   \n",
       "1           regist next txu capac auction   \n",
       "2       merchant power monthli free sampl   \n",
       "3                      eyeforenergi updat   \n",
       "4      deriv earli bird til march houston   \n",
       "...                                   ...   \n",
       "30687       cpu pain m edicati n ship d r   \n",
       "30688                    dn troubl f r ee   \n",
       "30689                   dr collin khumalo   \n",
       "30690        dear custom detail compromis   \n",
       "30691                      fwd great news   \n",
       "\n",
       "                                                    body  \n",
       "0      energi industri profession global chang associ...  \n",
       "1      regist next txu energi capac auction new regis...  \n",
       "2      merchant power monthli month s issu almost mw ...  \n",
       "3      welcom week s eyeforenergi updat refresh memor...  \n",
       "4      deriv energi profession two full day april ear...  \n",
       "...                                                  ...  \n",
       "30687  arrghh west amnstv amlsmith basu petrom qureai...  \n",
       "30688  dn troubl f r ee angiospasma zekauskasa anarti...  \n",
       "30689  dr collin khumalo attn mr presid dr collin khu...  \n",
       "30690  dear custom detail compromis dear custom recen...  \n",
       "30691  state shall without consent congress lay impos...  \n",
       "\n",
       "[29890 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Task_1_prepprocessed.csv')\n",
    "df = df.dropna()\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравним результаты, полученные при использовании трех различных способов векторизации:\n",
    "<ol>\n",
    "    <li>Базовый (в качестве предиктора используется только <code>body</code>).\n",
    "    <li>В качестве предикторов используем объединенные признаки <code>subject</code> и <code>body</code>, а также день недели, полученный из колонки <code>date</code>. \n",
    "    <li>Аналогично 1., только с использованием n-грамм.\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для базового алгоритма из загруженного датасета возьмем только колонку <code>body</code> и колонку <code>class</code> с обозначением класса сообщения (идет первой)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    df.iloc[:, 5], df.iloc[:,0], test_size=0.25, random_state=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы не модифицировать данные, использующиеся для базового алгоритма, сделаем глубокую копию данных для их дальнейшего преобразования. В частности, на копии произведем конкатенацию колонок `subject` и `body`. При разделении копии на тренировочный и тестовый наборы используем тот же `random_state`, что и для основого алгоритма, в целях сохранения соответствия полученных наборов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df.copy(deep = True)\n",
    "\n",
    "for i in range(len(df_copy)):\n",
    "    if df.iat[i, 4] != '':\n",
    "        try:\n",
    "            df_copy.iat[i, 5] = df_copy.iat[i, 4] + ' ' + df_copy.iat[i, 5]\n",
    "        except:\n",
    "            print(\"Something got wrong!\")\n",
    "            \n",
    "x_train_b, x_test_b, _, _ = train_test_split(\n",
    "    df_copy.iloc[:, [1, 5]], df_copy.iloc[:,0], test_size=0.25, random_state=100)\n",
    "\n",
    "# y_train_b и y_test_b совпадают с y_train, y_test. Хранить их отдельно надобности нет."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Генерация признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для базового алгоритма сначала из тренировочного набора данных составим словарь, используемый для векторизации и генерации признаков TF-IDF, во время преобразования тренировочного набора данных. Затем этот же словарь используем в функции трансформации тестового набора. Предлагаемый класс <code>TfidfVectorizer</code> используем с параметрами по умолчанию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_a = TfidfVectorizer()\n",
    "\n",
    "x_train_a = vectorizer_a.fit_transform(x_train)\n",
    "x_test_a = vectorizer_a.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для модифицированного алгоритма, где используется день недели, векторизацию произведем на колонке конкатенированных темы письма и содержания. К результату выполнения векторизации добавим колонку индексов дней недели. В данном случае векторизатор также инициализируем с параметрами по умолчанию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_b = TfidfVectorizer()\n",
    "# Добавляем к полученной в результате векторизации разреженной матрице столбец со значениями дней недели\n",
    "x_train_b = sp.sparse.hstack((vectorizer_b.fit_transform(x_train_b.iloc[:, 1]), x_train_b.iloc[:, 0].values.reshape(len(x_train_b.iloc[:, 0]),1)))\n",
    "x_test_b = sp.sparse.hstack((vectorizer_b.transform(x_test_b.iloc[:, 1]), x_test_b.iloc[:, 0].values.reshape(len(x_test_b.iloc[:, 0]),1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В третьем сценарии, где вместо слов используются биграммы для генерации признаков TF-IDF, при инициализации векторизатора укажем параметр <code>ngram_range = (2, 2)</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_c = TfidfVectorizer(ngram_range = (2, 2))\n",
    "\n",
    "x_train_c = vectorizer_c.fit_transform(x_train)\n",
    "x_test_c = vectorizer_c.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Классификация\n",
    "\n",
    "Инициализируем три классификатора с одинаковыми параметрами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=10,\n",
       "                       oob_score=False, random_state=2000, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_a = RandomForestClassifier(random_state=2000, n_jobs=10, n_estimators=10)\n",
    "rfc_b = RandomForestClassifier(random_state=2000, n_jobs=10, n_estimators=10)\n",
    "rfc_c = RandomForestClassifier(random_state=2000, n_jobs=10, n_estimators=10)\n",
    "\n",
    "rfc_a.fit(x_train_a, y_train)\n",
    "rfc_b.fit(x_train_b, y_train)\n",
    "rfc_c.fit(x_train_c, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Расчет метрик\n",
    "Для получения метрик удобнее всего воспользоваться модулем `sklearn.metrics`. Выполним предсказания на тестовых данных и выполним оценку полученных моделей для трех случаев."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.947     0.989     0.968      3962\n",
      "           1      0.987     0.938     0.962      3511\n",
      "\n",
      "    accuracy                          0.965      7473\n",
      "   macro avg      0.967     0.964     0.965      7473\n",
      "weighted avg      0.966     0.965     0.965      7473\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.957     0.987     0.972      3962\n",
      "           1      0.985     0.950     0.967      3511\n",
      "\n",
      "    accuracy                          0.970      7473\n",
      "   macro avg      0.971     0.969     0.970      7473\n",
      "weighted avg      0.970     0.970     0.970      7473\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.968     0.959     0.964      3962\n",
      "           1      0.954     0.964     0.959      3511\n",
      "\n",
      "    accuracy                          0.962      7473\n",
      "   macro avg      0.961     0.962     0.961      7473\n",
      "weighted avg      0.962     0.962     0.962      7473\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_a = rfc_a.predict(x_test_a)\n",
    "y_pred_b = rfc_b.predict(x_test_b)\n",
    "y_pred_c = rfc_c.predict(x_test_c)\n",
    "\n",
    "\n",
    "print(classification_report(y_test, y_pred_a, digits=3))\n",
    "print(classification_report(y_test, y_pred_b, digits=3))\n",
    "print(classification_report(y_test, y_pred_c, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для примера сравним первые два сценирия с точки зрения FPR и precision.\n",
    "Для получения FPR достаточно сгенерировать confusion matrix и рассчитать его на основе значений из матрицы, в то время как precision может быть получен с помощью отдельной функции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference in FPR: 0.0020191822311963654\n",
      "Difference in precision: -0.0021729832071559763\n"
     ]
    }
   ],
   "source": [
    "tn_a, fp_a, _, _  = confusion_matrix(y_test, y_pred_a).ravel()\n",
    "tn_b, fp_b, _, _ = confusion_matrix(y_test, y_pred_b).ravel()\n",
    "\n",
    "fpr_a = fp_a / (fp_a + tn_a)\n",
    "fpr_b = fp_b / (fp_b + tn_b)\n",
    "\n",
    "pr_a = precision_score(y_test, y_pred_a)\n",
    "pr_b = precision_score(y_test, y_pred_b)\n",
    "\n",
    "print(f'Difference in FPR: {fpr_b - fpr_a}')\n",
    "print(f'Difference in precision: {pr_b - pr_a}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
